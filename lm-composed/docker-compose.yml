version: "3.8"

services:
  lm-api:
    build:
      context: ../lm-api
      dockerfile: Dockerfile
    container_name: lm-api
    environment:
      DATABASE_HOST: db-lm-api
      DATABASE_USER: compose-db-api-user
      DATABASE_PSWD: compose-db-api-pswd
      DATABASE_NAME: compose-db-api-name
      DATABASE_PORT: 5432
      ARMASEC_DOMAIN: keycloak.local:8080/realms/lm-local
      ARMASEC_USE_HTTPS: false
      ARMASEC_DEBUG: false
      LOG_LEVEL: DEBUG
    ports: ["7000:8000"]
    command: uvicorn lm_api.main:app --reload --workers 1 --host 0.0.0.0 --port 8000
    healthcheck:
      test: curl --fail http://localhost:8000/lm/health || exit 1
      interval: 5s
      retries: 10
      timeout: 5s
    depends_on:
      migration:
        condition: service_completed_successfully
      keycloak.local:
        condition: service_healthy
    networks:
      - lm-net
    volumes:
      - ../lm-api/lm_api:/app/lm_api

  migration:
    build:
      context: ../lm-api
      dockerfile: Dockerfile-ci
    container_name: migration
    environment:
      DATABASE_HOST: db-lm-api
      DATABASE_USER: compose-db-api-user
      DATABASE_PSWD: compose-db-api-pswd
      DATABASE_NAME: compose-db-api-name
      ARMASEC_DOMAIN: keycloak.local:8080/realms/lm-local
      ARMASEC_USE_HTTPS: false
      LOG_LEVEL: DEBUG
    command: uv run python -m alembic -c alembic/alembic.ini upgrade head
    depends_on:
      db-lm-api:
        condition: service_healthy
    networks:
      - lm-net

  db-lm-api:
    image: postgres:13-alpine
    container_name: db-lm-api
    environment:
      POSTGRES_USER: compose-db-api-user
      POSTGRES_PASSWORD: compose-db-api-pswd
      POSTGRES_DB: compose-db-api-name
    ports: ["5434:5432"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lm-net

  lm-simulator-api:
    build:
      context: ../lm-simulator-api
      dockerfile: ./Dockerfile
    container_name: lm-simulator-api
    environment:
      DATABASE_HOST: db-lm-simulator-api
      DATABASE_USER: compose-db-sim-user
      DATABASE_PSWD: compose-db-sim-pswd
      DATABASE_NAME: compose-db-sim-name
      DATABASE_PORT: 5432
    ports: ["8001:8000"]
    command: uvicorn lm_simulator_api.main:app --reload --workers 1 --host 0.0.0.0 --port 8000
    healthcheck:
      test: curl --fail http://localhost:8000/lm-sim/health || exit 1
      interval: 5s
      retries: 10
      timeout: 5s
    depends_on:
      db-lm-simulator-api:
        condition: service_healthy
    networks:
      - lm-net

  db-lm-simulator-api:
    image: postgres:13-alpine
    container_name: db-lm-simulator-api
    environment:
      POSTGRES_USER: compose-db-sim-user
      POSTGRES_PASSWORD: compose-db-sim-pswd
      POSTGRES_DB: compose-db-sim-name
    ports: ["5435:5432"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lm-net

  keycloak.local:
    image: keycloak/keycloak:18.0.0
    container_name: keycloak
    environment:
      - KEYCLOAK_ADMIN=admin
      - KEYCLOAK_ADMIN_PASSWORD=admin
      - KC_HEALTH_ENABLED=true
    ports: ["8081:8080"]
    command: ["start-dev", "--import-realm"]
    restart: always
    healthcheck:
      test: curl --fail http://localhost:8080/health/ready || exit 1
      interval: 5s
      retries: 10
      timeout: 5s
    networks:
      - lm-net
    volumes:
      - kc-realm-files:/opt/keycloak/data/import/
      - ./etc/lm-local.json:/opt/keycloak/data/import/lm-local.json

  mysql:
    image: mysql:5.7
    container_name: mysql
    hostname: mysql
    environment:
      - MYSQL_RANDOM_ROOT_PASSWORD=yes
      - MYSQL_DATABASE=slurm_acct_db
      - MYSQL_USER=slurm
      - MYSQL_PASSWORD=password
    networks:
      - lm-net
    volumes:
      - var_lib_mysql:/var/lib/mysql

  slurmctld:
    build:
      context: .
      dockerfile: Dockerfile-slurm
      args:
        - JWT_SECRET=${JWT_SECRET:-supersecret}
    image: slurm-docker-cluster
    container_name: slurmctld
    hostname: slurmctld
    environment:
      LM_AGENT_BACKEND_BASE_URL: http://lm-api:8000
      LM_AGENT_LOG_BASE_DIR: /var/log/license-manager-agent
      LM_AGENT_CACHE_DIR: /var/cache/license-manager-agent
      LM_AGENT_LOG_LEVEL: DEBUG
      LM_AGENT_OIDC_DOMAIN: keycloak.local:8080/realms/lm-local
      LM_AGENT_OIDC_CLIENT_ID: local-slurm
      LM_AGENT_OIDC_CLIENT_SECRET: PNy6e5CflHCsQVRcBx3rDpyUdam9n8nv
      LM_AGENT_OIDC_USE_HTTPS: false
      LM_AGENT_LMUTIL_PATH: /app/lm-agent/.venv/bin/lmutil
      LM_AGENT_RLMUTIL_PATH: /app/lm-agent/.venv/bin/rlmutil
      LM_AGENT_LSDYNA_PATH: /app/lm-agent/.venv/bin/lstc_qrun
      LM_AGENT_LMXENDUTIL_PATH: /app/lm-agent/.venv/bin/lmxendutil
      LM_AGENT_OLIXTOOL_PATH: /app/lm-agent/.venv/bin/olixtool
      LM_AGENT_DSLICSRV_PATH: /app/lm-agent/.venv/bin/DSLicSrv
      LM_AGENT_LM_USER: root
      LM_AGENT_STAT_INTERVAL: 60
    expose: ["6817"]
    command: ["slurmctld"]
    depends_on:
      lm-api:
        condition: service_healthy
      lm-simulator-api:
        condition: service_healthy
    networks:
      - lm-net
    volumes:
      - etc_munge:/etc/munge
      - var_log_slurm:/var/log/slurm
      - ./slurm-fake-nfs:/nfs
      - ./slurm-work-dir:/slurm-work-dir
      - ../lm-agent/lm_agent/:/app/lm-agent/lm_agent
      - ../lm-agent/pyproject.toml:/app/lm-agent/pyproject.toml
      - ../lm-agent/uv.lock:/app/lm-agent/uv.lock
      - ../lm-agent/README.md:/app/lm-agent/README.md
      - ../lm-simulator/lm_simulator/:/app/lm-simulator/lm_simulator
      - ../lm-simulator/pyproject.toml:/app/lm-simulator/pyproject.toml
      - ../lm-simulator/uv.lock:/app/lm-simulator/uv.lock
      - ../lm-simulator/README.md:/app/lm-simulator/README.md
      - ./etc/lm-config/populate-lm-api.py:/app/populate-lm-api.py
      - ./etc/lm-config/populate-lm-simulator-api.py:/app/populate-lm-simulator-api.py
      - ./etc/lm-config/seed-license-in-slurm.py:/app/seed-license-in-slurm.py
      - ./etc/lm-config/configure-prolog-epilog.py:/app/configure-prolog-epilog.py
      - ./etc/slurm-config/slurmctld_prolog.sh:/app/slurmctld_prolog.sh
      - ./etc/slurm-configslurmctld_epilog.sh:/app/slurmctld_epilog.sh
      - ./etc/job_example.py:/nfs/job_example.py

  slurmdbd:
    build:
      context: .
      dockerfile: Dockerfile-slurm
    image: slurm-docker-cluster
    container_name: slurmdbd
    hostname: slurmdbd
    expose: ["6819"]
    command: ["slurmdbd"]
    volumes:
      - etc_munge:/etc/munge
      - var_log_slurm:/var/log/slurm
      - ./slurm-fake-nfs:/nfs
      - ./slurm-work-dir:/slurm-work-dir
    depends_on:
      - slurmctld
      - mysql
    networks:
      - lm-net

  c1:
    privileged: true
    build:
      context: .
      dockerfile: Dockerfile-slurm
    image: slurm-docker-cluster
    container_name: c1
    hostname: c1
    expose: ["6818"]
    command: ["slurmd"]
    depends_on:
      - slurmctld
    networks:
      - lm-net
    volumes:
      - etc_munge:/etc/munge
      - var_log_slurm:/var/log/slurm
      - ./slurm-fake-nfs:/nfs
      - ./slurm-work-dir:/slurm-work-dir

  c2:
    privileged: true
    build:
      context: .
      dockerfile: Dockerfile-slurm
    image: slurm-docker-cluster
    container_name: c2
    hostname: c2
    expose: ["6818"]
    command: ["slurmd"]
    depends_on:
      - slurmctld
    networks:
      - lm-net
    volumes:
      - etc_munge:/etc/munge
      - var_log_slurm:/var/log/slurm
      - ./slurm-fake-nfs:/nfs
      - ./slurm-work-dir:/slurm-work-dir

  slurmrestd:
    build:
      context: .
      dockerfile: Dockerfile-slurm
    image: slurm-docker-cluster
    container_name: slurmrestd
    hostname: slurmrestd
    environment:
      - SLURMRESTD_SECURITY=disable_unshare_files,disable_unshare_sysv,disable_user_check
      - SLURM_JWT=daemon
    ports: ["6820:6820"]
    expose: ["6820"]
    command: ["slurmrestd"]
    depends_on:
      - slurmctld
    networks:
      - lm-net
    volumes:
      - etc_munge:/etc/munge
      - var_log_slurm:/var/log/slurm
      - ./slurm-fake-nfs:/nfs
      - ./slurm-work-dir:/slurm-work-dir

volumes:
  postgres_data:
  kc-realm-files:
  etc_munge:
  var_lib_mysql:
  var_log_slurm:

networks:
  lm-net:
    driver: bridge
