{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>An Omnivector initiative</p> <p></p>"},{"location":"#welcome-to-the-license-manager-documentation","title":"Welcome to the License Manager documentation!","text":"<p>The License Manager is a license scheduling middleware that operates as an interface between an HPC cluster and one or more 3rd party license servers. The License Manager introduces the concept of \"license bookings\" which are used to provide an alternate source of truth for what licenses are actually available.</p>"},{"location":"architecture/","title":"License Manager Architecture","text":"<p>The License Manager is based on a client/backend architecture. The backend consists of a RESTful API built with Python over a PostgreSQL database. The client consists of a timed reconcile job that runs on the control node in the cluster and a prolog integration to Slurm.</p>"},{"location":"architecture/#license-manager-agent","title":"License Manager Agent","text":"<p>The <code>License Manager Agent</code> is responsible for keeping the local cluster license totals in sync with the the 3rd party license server totals. It's also responsible for making booking requests to the <code>License Manager API</code> when Slurm is configured to use the <code>PrologSlurmctld</code> script provided by <code>License Manager Agent</code>.</p>"},{"location":"architecture/#reconciliation","title":"Reconciliation","text":"<p>For each license tracked by License Manager, the <code>License Manager Agent</code> will periodically poll the license servers to get the usage information and store it in the <code>License Manager API</code>. The <code>stat-interval</code> is the period of time between each reconciliation and can be configured in the <code>License Manager Agent</code> configuration file.</p> <p>The information in the <code>License Manager API</code> is used by the reconciliation process to update the license counters in Slurm. This is done by creating a reservation to represent the licenses used in the license server.</p> <p>This reservation is not meant to be consumed by users nor jobs; it's only a representation of the licenses in use. The reservation is created by the user configured in the <code>License Manager Agent</code> configuration file. The user must have a user account in the Slurm cluster and have <code>operator</code> privilege level to manage reservations.</p>"},{"location":"architecture/#bookings","title":"Bookings","text":"<p>The <code>License Manager Agent</code> is also responsible for making booking requests to the <code>License Manager API</code> when Slurm is configured to use the <code>PrologSlurmctld</code> script provided by <code>License Manager Agent</code>.</p> <p>Each job submitted to Slurm will trigger the <code>PrologSlurmctld</code> script that makes a request to the <code>License Manager API</code> to book the needed licenses prior to the allocation of the job. The booking ensures that the licenses are available for the job to use by taking into consideration the licenses booked for other jobs and the license usage in the license server.</p> <p>If the booking cannot be made, the job will be kept in the queue until there are enough licenses available to satisfy the booking request.</p>"},{"location":"architecture/#grace-time","title":"Grace time","text":"<p>A job can take some time to check out the license from the license server after it is submitted to Slurm. Thus, each license has a <code>grace time</code> period that is used to indicate how long a booking will be retained. After the <code>grace time</code> expires, the booking is deleted. This means that the license was checked out from the license server and doesn't need a booking anymore.</p>"},{"location":"architecture/#license-manager-api","title":"License Manager API","text":"<p>The <code>License Manager API</code> provides a RESTful API where licenses and bookins are tracked. The <code>License Manager Agent</code> uses this API to store the license usage information and to process the booking requests. The <code>License Manager CLI</code> interacts with this API to add new configurations and to check the usage information for each tracked license.</p> <p>The API is also responsible for verifying if the booking requests can be satisfied by accounting for bookings already made and the license usage in the license server.</p> <p>The API contains 6 entities that have relationship among them. This means that some of the resources need to be created before others can be created as well.</p> <pre><code>    erDiagram\n        Bookings {\n            int id pk\n            int job_id pk\n            int feature_id pk\n            int quantity\n        }\n        Features {\n            int id pk,fk\n            int config_id pk\n            int product_id pk\n            int reserved\n            int total\n            int used\n            str name \n        }\n        Products {\n            int id pk\n            str name\n        }\n        Jobs {\n            int id pk, fk\n            str slurm_job_id\n            str cluster_client_id\n            str username\n            str lead_host\n        }\n        Configurations {\n            int id pk\n            str name\n            str cluster_client_id\n            int grace_time\n            enum[str] type\n        }\n        LicenseServers {\n            int id pk\n            int config_id fk\n            str host\n            int port\n        }\n        Jobs ||--o{ Bookings : \"\"\n        Features ||--o{ Bookings : \"\"\n        Products ||--o{ Features : \"\"\n        Configurations ||--|{ Features : \"\"\n        Configurations ||--|{ LicenseServers : \"\"</code></pre>"},{"location":"architecture/#configurations","title":"Configurations","text":"<p>The <code>Configuration</code> resource holds the information for a set of features that are available on the same license server.</p> <p>A configuration is attached to a cluster and can have <code>n</code> features attached to it. It also defines the license type, the license server host addresses and the grace time period. The license type identifies the provider of the license server.</p> <p>The following license server types are supported:</p> <ul> <li>FlexLM</li> <li>RLM</li> <li>LS-Dyna</li> <li>LM-X</li> <li>OLicense</li> </ul> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/configurations</code></li> <li>GET <code>/lm/configurations</code></li> <li>GET <code>/lm/configurations/by_client_id</code></li> <li>GET <code>/lm/configurations/{id}</code></li> <li>PUT <code>/lm/configurations/{id}</code></li> <li>DEL <code>/lm/configurations/{id}</code></li> </ul> <p>The endpoint <code>by_client_id</code> extracts the <code>cluster_client_id</code> from the request and returns the configurations that belong to the cluster.</p> <p>Payload example for POST:</p> <pre><code>{\n\"name\": \"configuration-name\",\n\"cluster_client_id\": \"cluster-client-id\", \"grace_time\": 60,\n\"type\": \"flexlm\"\n}\n</code></pre> <p>After creating a configuration, the license servers and features can be added.</p>"},{"location":"architecture/#license-servers","title":"License Servers","text":"<p>The <code>License Server</code> resource represents the actual license server where the license is installed.</p> <p>A license server has a host and a port, and needs to be attached to a configuration. Each configuration can have <code>n</code> license servers, as long as they provide the same data (mirrored for redundancy).</p> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/license_servers</code></li> <li>GET <code>/lm/license_servers</code></li> <li>GET <code>/lm/license_servers/{id}</code></li> <li>PUT <code>/lm/license_servers/{id}</code></li> <li>DEL <code>/lm/license_servers/{id}</code></li> </ul> <p>Payload example for POST:</p> <pre><code>{\n\"config_id\": 1,\n\"host\": \"licserv0001\",\n\"port\": 1234\n}\n</code></pre>"},{"location":"architecture/#products","title":"Products","text":"<p>The <code>Product</code> resource represents the product name of the license.</p> <p>Each license is identified as <code>product.feature@license_server_type</code>. To create a <code>Feature</code>, a <code>Product</code> needs to be created first.</p> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/products</code></li> <li>GET <code>/lm/products</code></li> <li>GET <code>/lm/products/{id}</code></li> <li>PUT <code>/lm/products/{id}</code></li> <li>DEL <code>/lm/products/{id}</code></li> </ul> <p>Payload example for POST:</p> <pre><code>{\n\"name\": \"abaqus\"\n}\n</code></pre>"},{"location":"architecture/#features","title":"Features","text":"<p>The <code>Feature</code> resource represents the licenses in the cluster.</p> <p>Each <code>Feature</code> is attached to a <code>Configuration</code> and a <code>Product</code>.</p> <p>The feature has a <code>reserved</code> value, that represents how many licenses should be reserved for usage in desktop applications. The amount of licenses reserved is not used by the cluster.</p> <p>The <code>License Manager Agent</code> polls the license server to populate the <code>used</code> and <code>total</code> values. The information stored includes the total number of licenses available and how many licenses are in use.</p> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/features</code></li> <li>GET <code>/lm/features</code></li> <li>GET <code>/lm/features/{id}</code></li> <li>PUT <code>/lm/features/{id}</code></li> <li>PUT <code>/lm/features/by_client_id</code></li> <li>DEL <code>/lm/features/{id}</code></li> </ul> <p>The endpoint <code>by_client_id</code> extracts the <code>cluster_client_id</code> from the request and updates the feature for that cluster.</p> <p>This endpoint is needed since there can be multiple licenses with the same name in different clusters.</p> <p>Payload example for POST:</p> <pre><code>{\n\"name\": \"abaqus\",\n\"product_id\": 1,\n\"config_id\": 1,\n\"reserved\": 50,\n}\n</code></pre>"},{"location":"architecture/#jobs","title":"Jobs","text":"<p>The <code>Job</code> resource represents the jobs submitted to the cluster.</p> <p>When a job is intercepted by the <code>PrologSlurmctld</code> script, the job is created automatically.</p> <p>Each <code>Job</code> can have <code>n</code> <code>Bookings</code> attached to it. If the job requires licenses, a <code>Booking</code> is created for each license. Once the job finishes, the <code>EpilogSlurmctld</code> deletes the job from the API, along with its bookings.</p> <p>Since the <code>slurm_job_id</code> is not unique across clusters, each job is identified by the <code>cluster_client_id</code> alongside the <code>slurm_job_id</code>.</p> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/jobs</code></li> <li>GET <code>/lm/jobs</code></li> <li>GET <code>/lm/jobs/by_client_id</code></li> <li>GET <code>/lm/jobs/{id}</code></li> <li>GET <code>/lm/jobs/slurm_job_id/{slurm_job_id}</code></li> <li>DEL <code>/lm/jobs/{id}</code></li> <li>DEL <code>/lm/jobs/slurm_job_id/{slurm_job_id}</code></li> </ul> <p>The endpoint <code>by_client_id</code> extracts the <code>cluster_client_id</code> from the request and returns the jobs that belong to the cluster.</p> <p>The in the POST endpoint, the parameter <code>cluster_client_id</code> is optional. If it's not provided, the <code>cluster_client_id</code> is extracted from the request.</p> <p>Payload example for POST:</p> <pre><code>{\n\"slurm_job_id\": \"123\",\n\"cluster_client_id\": \"cluster-client-id\",\n\"username\": \"user123\",\n\"lead_host\": \"host1\"\n}\n</code></pre>"},{"location":"architecture/#bookings_1","title":"Bookings","text":"<p>The <code>Booking</code> resource is responsible for booking licenses for a specific job.</p> <p>The booking ensures the job will have enough licenses to be used when the <code>grace time</code> is reached. <code>License Manager Agent</code> stores the information about the booking requests made by Slurm when the <code>PrologSlurmctld</code> script is used.</p> <p>Each <code>Booking</code> is attached to a <code>Job</code>. The <code>job_id</code> parameter identifies the job in the API, and is different from the <code>slurm_job_id</code> that idenfies it in the cluster.</p> <p>Endpoints available:</p> <ul> <li>POST <code>/lm/bookings</code></li> <li>GET <code>/lm/bookings</code></li> <li>GET <code>/lm/bookings/{id}</code></li> <li>DEL <code>/lm/bookings/{id}</code></li> </ul> <p>Payload example for POST:</p> <pre><code>{\n\"job_id\": 1,\n\"feature_id\": 1,\n\"quantity\": 50\n}\n</code></pre>"},{"location":"architecture/#license-manager-cli","title":"License Manager CLI","text":"<p>The <code>License Manager CLI</code> is a client to interact with the <code>License Manager API</code>.</p> <p>It can be used to add new configurations to the API and to check the usage information for each tracked license.</p> <p>The <code>Jobs</code> and <code>Bookings</code> are read only. The remaining resources can be edited by users with permission to do so.</p>"},{"location":"architecture/#global-commands","title":"Global commands","text":"Command Description lm-cli login Generate a URL for logging in via browser lm-cli show-token Print your access token (created after logging in) lm-cli logout Logout and remove your access token"},{"location":"architecture/#configuration-commands","title":"Configuration commands","text":"Command Description lm-cli configurations list List all configurations lm-cli configurations list--search &lt;search string&gt; Search configurations with the specified string lm-cli configurations list--sort-field &lt;sort field&gt; Sort configurations by the specified field lm-cli configurations list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort configurations by the specified order lm-cli configurations get-one--id &lt;configuration id&gt; List the configuration with the specified id lm-cli configurations create--name &lt;configuration name&gt;--cluster-client-id &lt;OIDC client_id of the cluster where the configuration applies&gt;--grace-time &lt;grace time in seconds&gt;--license-server-type &lt;license server type&gt; Create a new configuration lm-cli configurations delete--id &lt;id to delete&gt; Delete the configuration with the specified id"},{"location":"architecture/#license-server-commands","title":"License server commands","text":"Command Description lm-cli license-servers list List all license servers lm-cli license-servers list--search &lt;search string&gt; Search license servers with the specified string lm-cli license-servers list--sort-field &lt;sort field&gt; Sort license servers by the specified field lm-cli license-servers list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort license servers by the specified order lm-cli license-servers get-one--id &lt;license server id&gt; List the license server with the specified id lm-cli license-servers create--config-id &lt;id of the configuration to add the license server&gt;--host &lt;hostname of the license server&gt;--port &lt;port of the license server&gt; Create a new license server lm-cli license-servers delete--id &lt;id to delete&gt; Delete the license server with the specified id"},{"location":"architecture/#product-commands","title":"Product commands","text":"Command Description lm-cli products list List all products lm-cli products list--search &lt;search string&gt; Search products with the specified string lm-cli products list--sort-field &lt;sort field&gt; Sort products by the specified field lm-cli products list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort products by the specified order lm-cli products get-one--id &lt;product id&gt; List the product with the specified id lm-cli products create--name &lt;product name&gt; Create a new product lm-cli products delete--id &lt;id to delete&gt; Delete the product with the specified id"},{"location":"architecture/#feature-commands","title":"Feature commands","text":"Command Description lm-cli features list List all features lm-cli features list--search &lt;search string&gt; Search features with the specified string lm-cli features list--sort-field &lt;sort field&gt; Sort features by the specified field lm-cli features list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort features by the specified order lm-cli features get-one--id &lt;feature id&gt; List the feature with the specified id lm-cli features create--name &lt;feature name&gt;--product-id &lt;id of the product of the license&gt;--config-id &lt;id of the configuration of the license&gt;--reserved &lt;how many licenses should be reserved for desktop environments&gt; Create a new feature lm-cli features delete--id &lt;id to delete&gt; Delete the feature with the specified id"},{"location":"architecture/#job-commands","title":"Job commands","text":"Command Description lm-cli jobs list List all jobs lm-cli jobs list--search &lt;search string&gt; Search jobs with the specified string lm-cli jobs list--sort-field &lt;sort field&gt; Sort jobs by the specified field lm-cli jobs list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort jobs by the specified order"},{"location":"architecture/#booking-commands","title":"Booking commands","text":"Command Description lm-cli bookings list List all bookings lm-cli bookings list--search &lt;search string&gt; Search bookings with the specified string lm-cli bookings list--sort-field &lt;sort field&gt; Sort bookings by the specified field lm-cli bookings list--sort-field &lt;sort field&gt;--sort-order &lt;ascending or descending&gt; Sort bookings by the specified order"},{"location":"development/","title":"Development","text":"<p>The <code>License Manager</code> application incorporates a mix of different services in docker and LXD containers. This text will attempt to define the procedure for initializing and running the different components.</p>"},{"location":"development/#pre-installation","title":"Pre-Installation","text":"<p>Before you get started, ensure you have the following pre-requisites installed on your machine:</p> <ul> <li>snapd</li> <li>charmcraft</li> <li>LXD (latest/stable)</li> <li>juju</li> <li>poetry</li> <li>docker-compose</li> <li>docker</li> </ul> <p>Additionally, assign the host machine's primary IP address to a variable <code>MY_IP</code>. We will use this value throughout the development environment setup process.</p> <pre><code>MY_IP=\"$(ip route get 1 | awk '{print $(NF-2);exit}')\"\n</code></pre>"},{"location":"development/#1-deploy-a-local-slurm-cluster-on-lxd","title":"1. Deploy a local SLURM cluster on LXD","text":"<p>Follow the upstream documentation to deploy a local LXD slurm cluster that we can use in development.</p> <p>The general idea is to run <code>juju deploy slurm</code>, following which, you will have a local slurm cluster to use in development.</p> <p>After the deployment of slurm has completed and settled, the environment should resemble the following:</p> <pre><code>Model                    Controller           Cloud/Region         Version  SLA          Timestamp\nlicense-manager-testing  localhost-localhost  localhost/localhost  2.9.17   unsupported  06:46:42Z\n\nApp              Version  Status  Scale  Charm            Store     Channel  Rev  OS      Message\npercona-cluster  5.7.20   active      1  percona-cluster  charmhub  stable   302  ubuntu  Unit is ready\nslurmctld        0.8.1    active      1  slurmctld        charmhub  stable    17  ubuntu  slurmctld available\nslurmd           0.8.1    active      1  slurmd           charmhub  stable    26  ubuntu  slurmd available\nslurmdbd         0.8.1    active      1  slurmdbd         charmhub  stable    15  ubuntu  slurmdbd available\nslurmrestd       0.8.1    active      1  slurmrestd       charmhub  stable    15  ubuntu  slurmrestd available\n\nUnit                Workload  Agent  Machine  Public address  Ports     Message\npercona-cluster/0*  active    idle   0        10.20.96.130    3306/tcp  Unit is ready\nslurmctld/0*        active    idle   1        10.20.96.57               slurmctld available\nslurmd/0*           active    idle   2        10.20.96.233              slurmd available\nslurmdbd/0*         active    idle   3        10.20.96.123              slurmdbd available\nslurmrestd/0*       active    idle   4        10.20.96.62               slurmrestd available\n\nMachine  State    DNS           Inst id        Series  AZ  Message\n0        started  10.20.96.130  juju-b71748-0  bionic      Running\n1        started  10.20.96.57   juju-b71748-1  focal       Running\n2        started  10.20.96.233  juju-b71748-2  focal       Running\n3        started  10.20.96.123  juju-b71748-3  focal       Running\n4        started  10.20.96.62   juju-b71748-4  focal       Running\n</code></pre> <p>Following the deployment, run the action to enlist the <code>slurmd</code> node and set it's state to idle.</p> <pre><code>juju run-action slurmd/0 node-configured\n</code></pre> <p>Lastly, validate that the node has successfully enlisted and the cluster is operational.</p> <pre><code>$ juju ssh slurmd/0 sinfo\nPARTITION  AVAIL  TIMELIMIT  NODES  STATE NODELIST\nosd-slurmd    up   infinite      1   idle juju-b71748-2\n\n$ juju ssh slurmd/0 srun -posd-slurmd hostname\njuju-b71748-2\n</code></pre> <p>The slurm cluster is now prepared for further configuration and use in <code>License Manager</code> development.</p>"},{"location":"development/#2-compose-the-license-manager-api","title":"2. Compose the License Manager API","text":"<p>Setting up the <code>License Manager API</code> for development is done in three steps:</p> <ol> <li>Clone the project to your local machine</li> <li>Run <code>docker-compose</code></li> <li>Initialize the database with a license configuration for testing.</li> </ol> <p>To get started, clone the <code>license-manager</code> repository from GitHub and run <code>make local</code>.</p> <pre><code>git clone https://github.com/omnivector-solutions/license-manager\ncd license-manager/backend/\nmake local\n</code></pre> <p>We should now see two running docker containers; <code>backend_license-manager_1</code> and <code>backend_postgres-back_1</code>.</p> <p><code>docker ps</code> shows:</p> <pre><code>$ docker ps\nCONTAINER ID   IMAGE                     COMMAND                  CREATED          STATUS                    PORTS                                   NAMES\na62719b6fa65   backend_license-manager   \"uvicorn lm_api.\u2026\"   13 minutes ago   Up 13 minutes             0.0.0.0:7000-&gt;80/tcp, :::7000-&gt;80/tcp   backend_license-manager_1\n3d5abbc7ffff   postgres                  \"docker-entrypoint.s\u2026\"   2 days ago       Up 13 minutes (healthy)   5432/tcp                                backend_postgres-back_1\n</code></pre> <p>From the output above, we see that port <code>7000</code> on our local machine is forwarded to the listening port of the <code>License Manager API</code> container (port <code>80</code>). This means we will make requests to our local host IP address at port <code>7000</code> in order to access the <code>License Manager API</code> HTTP endpoints.</p> <p>Now initialize the API with the following resources that we can use for testing:</p> <ol> <li>Configuration</li> <li>License server</li> <li>Product</li> <li>Feature</li> </ol> <pre><code>CONFIG_ID=$(curl -X 'POST' \\\n'http://'$MY_IP':7000/lm/configurations/' \\\n-H 'accept: application/json' \\\n-H 'Content-Type: application/json' \\\n-d '{\n  \"name\": \"Abaqus\",\n  \"cluster_client_id\": \"osd-cluster\",\n  \"grace_time\": 30,\n  \"type\": \"flexlm\"\n  }' | jq '.id')\ncurl -X 'POST' \\\n'http://'$MY_IP':7000/lm/license_servers/' \\\n-H 'accept: application/json' \\\n-H 'Content-Type: application/json' \\\n-d '{\n  \"config_id\": '$CONFIG_ID',\n  \"host\": \"myexampleflexlmhost.example.com\",\n  \"port\": 24000\n  }'\nPRODUCT_ID=$(curl -X 'POST' \\\n'http://'$MY_IP':7000/lm/products/' \\\n-H 'accept: application/json' \\\n-H 'Content-Type: application/json' \\\n-d '{\n  \"name\": \"abaqus\"\n  }' | jq '.id')\ncurl -X 'POST' \\\n'http://'$MY_IP':7000/lm/features/' \\\n-H 'accept: application/json' \\\n-H 'Content-Type: application/json' \\\n-d '{\n  \"name\": \"abaqus\",\n  \"product_id\": '$PRODUCT_ID',\n  \"config_id\": '$CONFIG_ID',\n  \"reserved\": 0\n  }'\n</code></pre> <p>You can check that the resources were successfully added by making a request to list the configurations in the database. (this list should contain the license you previously added.)</p> <pre><code>curl -X 'GET' \\\n'http://'$MY_IP':7000/lm/configurations' \\\n-H 'accept: application/json'\n</code></pre> <pre><code>[\n{\n\"id\": 1,\n    \"name\": \"Abaqus\",\n    \"cluster_client_id\": \"osd-cluster\",\n    \"features\": [\n{\n\"id\": 1,\n        \"name\": \"abaqus\",\n        \"product\": {\n\"id\": 1,\n          \"name\": \"abaqus\"\n},\n        \"config_id\": 1,\n        \"reserved\": 0,\n        \"total\": 0,\n        \"used\": 0\n}\n],\n    \"license_servers\": [\n{\n\"id\": 1,\n        \"config_id\": 1,\n        \"host\": \"myexampleflexlmhost.example.com\",\n        \"port\": 24000\n}\n],\n    \"grace_time\": 30,\n    \"type\": \"flexlm\"\n}\n]\n</code></pre> <p>The <code>License Manager API</code> is now configured and ready for use in the development environment.</p>"},{"location":"development/#3-compose-the-license-manager-simulator","title":"3. Compose the License Manager Simulator","text":"<p>To run the <code>License Manager Simulator</code> API, clone the repository and run <code>docker-compose up</code>.</p> <pre><code>git clone https://github.com/omnivector-solutions/license-manager-simulator\ncd license-manager-simulator/\ndocker-compose up\n</code></pre>"},{"location":"development/#4-add-the-license-manager-agent-to-the-cluster","title":"4. Add the License Manager Agent to the cluster","text":"<p>The final component we need to deploy is the <code>License Manager Agent</code>. The <code>License Manager Agent</code> is deployed to the same model as the slurm charms, and related to <code>slurmctld</code>.</p> <pre><code>git clone git@github.com:omnivector-solutions/charm-license-manager-agent\ncd charm-license-manager-agent/\nmake charm\n</code></pre> <p>The <code>make charm</code> command will produce a resultant charm artifact named <code>license-manager-agent.charm</code>. This is the charm that we will deploy.</p> <p>Before deploying the charm, create a <code>yaml</code> configuration file that contains the needed settings for the <code>License Manager Agent Charm</code>. The config should look something like this:</p> <pre><code>license-manager-agent:\nlog-level: DEBUG\nstat-interval: 30\nlicense-manager-backend-base-url: \"http://\"$MY_IP\":7000\"\nlmutil-path: \"/usr/local/bin/lmutil\"\nrlmutil-path: \"/usr/local/bin/rlmutil\"\nlsdyna-path: \"/usr/local/bin/lstc_qrun\"\nlmxendutil-path: \"/usr/local/bin/lmxendutil\"\nolixtool-path: \"/usr/local/bin/olixtool\"\noidc-domain: \"your-oidc-domain\"\noidc-audience: \"your-oidc-audience\"\noidc-client-id: \"your-oidc-client-id\"\noidc-client-secret: \"your-oidc-client-secret\"\nsentry-dsn: \"\"\n</code></pre> <p>Make sure to substitute the correct values into the new <code>license-manager-agent.yaml</code> configuration file (especially the IP address of your host machine). You'll also need to provision an OIDC instance to authenticate against the backend API.</p> <p>Now that we have the charm artifact (<code>license-manager-agent.charm</code>) and the config file for the charm (<code>license-manager-agent.yaml</code>), we are ready to deploy.</p> <p>Using <code>juju</code>, deploy the <code>license-manager-agent</code> charm to the model, specifying the config file as an argument to the deploy command.</p> <pre><code>juju deploy ./license-manager-agent.charm \\\n--config ./license-manager-agent.yaml --series focal\n</code></pre> <p>After the deploy, make sure to relate the charm to the juju-info and prolog-epilog interface.</p> <pre><code>juju relate license-manager-agent:juju-info slurmctld\njuju relate license-manager-agent:prolog-epilog slurmctld\n</code></pre>"},{"location":"development/#5-additional-modifications","title":"5. Additional Modifications","text":"<p>At this point you should have 3 systems running:</p> <ol> <li>Slurm cluster in LXD</li> <li>License Manager Simulator</li> <li>License Manager Backend</li> </ol> <p>Once the systems have been successfully deployed you will need to apply the post deployment configurations. These configurations will ensure that your slurm cluster has a fake license server client and available licenses to be used by the fake application (which will be run as a batch script).</p>"},{"location":"development/#configuring-the-license-server-client","title":"Configuring the license server client","text":"<p>The <code>License Manager Simulator</code> has a script and a template for each license server supported (FlexLM, RLM, LS-Dyna, LM-X and OLicense). The script requests license information from the <code>License Manager Simulator</code> API and renders it in the template, simulating the output from the real license server. These files need to be copied to the <code>License Manager Agent</code> machine.</p> <p>You also need to add licenses to the Slurm cluster and to the simulator API. To use the simulated licenses, there's an application script, which requests a license to the simulator API, sleeps for a few seconds, and return the license. This application can be submitted as a job using a batch file. These files need to be copied to the slurmd machine.</p> <p>To set up everything needed to use the simulator, use the make setup command available in the <code>License Manager Simulator</code> project. This commands expects as an argument the <code>License Manager Simulator</code> API IP address.</p> <pre><code>cd license-manager-simulator/\nmake setup lm_sim_ip=http://$MY_IP:8000\n</code></pre>"},{"location":"development/#using-the-simulated-license-servers","title":"Using the simulated license servers","text":"<p>With the environment configured, you'll have one simulated license for each license server supported:</p> <ol> <li>abaqus.abaqus for FlexLM</li> <li>converge.super for RLM</li> <li>mppdyna.mppdyna for LS-Dyna</li> <li>hyperworks.hyperworks for LM-X</li> <li>cosin.ftire_adams for OLicense</li> </ol> <p>These licenses will be available in the simulated license servers. You can check it by executing <code>lmutil</code>, <code>rlmutil</code>, <code>lstc_qrun</code>, <code>lmxendutil</code> and <code>olixtool.lin</code> files.</p> <pre><code>juju ssh license-manager-agent/0\nsource /srv/license-manager-agent-venv/bin/activate\n/srv/license-manager-agent-venv/lib/python3.8/site-packages/bin/lmutil\n</code></pre> <p>The output should display the \"abaqus.abaqus\" license that was added to the <code>License Manager Simulator</code>:</p> <pre><code>lmutil - Copyright (c) 1989-2012 Flexera Software LLC. All Rights Reserved.\nFlexible License Manager status on Thu 10/29/2020 17:44\n\nLicense server status: server1,server2,server3\n    License file(s) on server1: f:\\flexlm\\AbaqusLM\\License\\license.dat:\n\nserver1: license server UP v11.13\nserver2: license server UP (MASTER) v11.13\nserver3: license server UP v11.13\n\nVendor daemon status (on server2):\n  FakeLM: UP v11.13\n\nFeature usage info:\n\nUsers of abaqus:  (Total of 1000 licenses issued;  Total of 0 licenses in use)\n\"abaqus\" v62.2, vendor: FakeLM\n\nfloating license\n</code></pre>"},{"location":"development/#seeding-the-batch-script-and-fake-application","title":"Seeding the batch script and fake application","text":"<p>To test the <code>License Manager</code>, there's a fake application and a batch script. These files are available at the <code>/tmp</code> folder in the <code>slurmd</code> machine. The fake application makes a request to the <code>License Manager Simulator</code> API to book 42 <code>abaqus</code> licenses, sleeps for a few seconds, and then deletes the booking after. The batch script will be responsible for scheduling the fake application job in the slurm cluster.</p> <p>To run the job, use the <code>sbatch</code> command.</p> <pre><code>juju ssh slurmd/0 sbatch /tmp/batch.sh\n</code></pre> <p>To use other licenses, change the license's name in the <code>application.sh</code> and <code>batch.sh</code> file.</p>"},{"location":"development/#6-validation","title":"6. Validation","text":"<p>After following the steps above, you should have a working development environment. To validate that it is indeed working, submit a job to slurm (using the batch script) and check <code>License Manager API</code>. Make a request to the <code>features</code> endpoint.</p> <pre><code>curl -X 'GET' \\\n'http://'$MY_IP':7000/lm/features' \\\n-H 'accept: application/json'\n</code></pre> <p>You should see that the <code>used</code> value for the license was updated with the value used in the job (42).</p> <pre><code>[\n{\n\"id\": 1,\n    \"name\": \"abaqus\",\n    \"product\": {\n\"id\": 1,\n      \"name\": \"abaqus\"\n},\n    \"config_id\": 10\n\"reserved\": 0,\n    \"total\": 1000,\n    \"used\": 42\n}\n]\n</code></pre> <p>You also should have a new job created. To verify this, make a request to the <code>jobs</code> endpoint.</p> <pre><code>curl -X 'GET' \\\n'http://'$MY_IP:7000'/lm/jobs' \\\n-H 'accept: application/json'\n</code></pre> <p>The job should contain information about the job and also how many licenses were booked by the job.</p> <pre><code>[\n{\n\"id\": 1,\n    \"slurm_job_id\": \"1\",\n    \"cluster_client_id\": \"osd-cluster\",\n    \"username\": \"ubuntu\",\n    \"lead_host\": \"juju-d9201d-2\",\n    \"bookings\": [\n{\n\"id\": 1,\n        \"job_id\": 1,\n        \"feature_id\": 1,\n        \"quantity\": 42\n}\n]\n}\n]\n</code></pre> <p>Wait for a few seconds (for the reconcile to run) and check again. The job and the booking should be deleted and the <code>used</code> value will return to its original quantity.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>To run License Manager you will need three different systems:</p> <ol> <li>Slurm cluster (where <code>License Manager Agent</code> runs)</li> <li>License servers (FlexLM, RLM, LS-Dyna, LM-X, OLicense or License Manager Simulator)</li> <li>API with license information (<code>License Manager API</code>)</li> </ol>"},{"location":"getting_started/#slurm-cluster","title":"Slurm cluster","text":"<p>License Manager is designed to work with Slurm. To learn how to create a Slurm cluster, please refer to the Omnivector Slurm Distribution documentation.</p>"},{"location":"getting_started/#license-servers","title":"License servers","text":"<p>License Manager supports the following license servers:</p> <ul> <li>FlexLM</li> <li>RLM</li> <li>LS-Dyna</li> <li>LM-X</li> <li>OLicense</li> </ul> <p>You need to have the license server installed and working on a path that is accessible to the <code>License Manager Agent</code>. The path for each license server binary is configurable in the <code>License Manager Agent</code> charm. In case you don't have a license server, you can use the <code>License Manager Simulator</code> to simulate the output of a license server.</p>"},{"location":"getting_started/#license-manager-api","title":"License Manager API","text":"<p>The <code>License Manager API</code> is an API that stores license usage information gathered from the license servers by the agent's reconciliation process. This data is used to update the license counters in the cluster to reflect the actual usage of the licenses. For each license tracked by License Manager, you need to create a configuration in the API. This includes the license name, the license features, the license server type and location, and the grace time (how long it takes for the license to be checked out after the job starts).</p> <p>To learn how to set up each system needed, please refer to the Development section.</p>"}]}